{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578f58fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello word\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa3bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import TensorDataset, DataLoader \n",
    "from sklearn.model_selection import train_test_split \n",
    "import sys \n",
    "import os \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.manifold import TSNE \n",
    "from wordcloud import WorldCloud \n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Check if GPU is available \n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec22cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this for unzip and read the file\n",
    "try:\n",
    "    df=pd.read_csv(\"/content/test/IMDB Dataset.csv\")\n",
    "except:\n",
    "    # !wget https://github.com/SalvatoreRa/tutorial/blob/main/datasets/IMDB.zip?raw=true\n",
    "    # !unzip IMDB.zip?raw=true\n",
    "    pass\n",
    "\n",
    "df['sentiment_encoded'] = np.where(df['sentiment']=='positive',0,1)\n",
    "X,y = df['review'].values, df['sentiment_encoded'].values\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y, test_size=.2)\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,stratify=y_train, test_size=.1)\n",
    "y_train, y_val, y_test = np.array(y_train), np.array(y_val), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramFeatureExtractor:\n",
    "    \"\"\"Extracts N-gram features using TF-INDF vectorization\"\"\"\n",
    "\n",
    "    def __init__(self, ngram_range=(1,3), max_features=5000):\n",
    "        self.vectorizer = TfidVectorizer(\n",
    "            ngram_range=ngram_range,\n",
    "            max_features=max_features,\n",
    "            lowercase=True\n",
    "        )\n",
    "\n",
    "    def fit_transform(self, texts):\n",
    "        \"\"\"Fit vectorizer and transform texts to n-gram \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
